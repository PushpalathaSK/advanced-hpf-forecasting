{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49899daf",
   "metadata": {},
   "source": [
    "\n",
    "# Advanced Time Series Forecasting — Data Generation & Baseline Modeling\n",
    "\n",
    "**Contents**\n",
    "- Generate synthetic hierarchical daily sales data (5 regions × 20 stores × 3 years)\n",
    "- Fit baseline ETS (Holt–Winters) models per store\n",
    "- Produce bottom-up aggregates and region/total ETS forecasts\n",
    "- Reconcile forecasts (bottom-up + aggregate averaging)\n",
    "- Compute basic evaluation metrics (MASE, wMAPE)\n",
    "- Save outputs (CSV) for submission\n",
    "\n",
    "This notebook is prepared for the project submission. Run the cells sequentially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "os.makedirs(\"project_outputs\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Settings\n",
    "n_regions = 5\n",
    "stores_per_region = 20\n",
    "freq = \"D\"           # daily data\n",
    "years = 3\n",
    "periods = years * 365  # approx daily\n",
    "start_date = \"2018-01-01\"\n",
    "dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n",
    "\n",
    "regions = [f\"Region_{i+1}\" for i in range(n_regions)]\n",
    "stores = []\n",
    "for r in regions:\n",
    "    for s in range(1, stores_per_region+1):\n",
    "        stores.append(f\"{r}_Store_{s}\")\n",
    "\n",
    "# Seasonal patterns\n",
    "weekly_season = 10 + 5 * np.sin(2 * np.pi * (np.arange(periods) % 7) / 7)\n",
    "annual_season = 20 * np.sin(2 * np.pi * np.arange(periods) / 365.25)\n",
    "\n",
    "rows = []\n",
    "for i, store in enumerate(stores):\n",
    "    region = store.split(\"_Store_\")[0]\n",
    "    base = np.random.uniform(50, 300) + (i % 10) * 2\n",
    "    trend = np.random.uniform(-0.02, 0.1)\n",
    "    noise_scale = np.random.uniform(5, 30)\n",
    "    promo = np.zeros(periods)\n",
    "    for _ in range(np.random.poisson(3)):\n",
    "        start = np.random.randint(0, periods-30)\n",
    "        length = np.random.randint(3, 14)\n",
    "        promo[start:start+length] += np.random.uniform(20, 80)\n",
    "    series = base + trend * np.arange(periods) + weekly_season + annual_season + promo + np.random.normal(0, noise_scale, periods)\n",
    "    series = np.maximum(0, series).round(2)\n",
    "    df = pd.DataFrame({\"date\": dates, \"region\": region, \"store\": store, \"sales\": series})\n",
    "    rows.append(df)\n",
    "\n",
    "data = pd.concat(rows, ignore_index=True)\n",
    "data = data.sort_values([\"store\", \"date\"]).reset_index(drop=True)\n",
    "data.to_csv(\"project_outputs/generated_sales_long.csv\", index=False)\n",
    "pivot = data.pivot(index=\"date\", columns=\"store\", values=\"sales\")\n",
    "pivot.to_csv(\"project_outputs/generated_sales_wide.csv\", index=True)\n",
    "print('Generated dataset saved to project_outputs/ (generated_sales_long.csv and generated_sales_wide.csv)')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ETS baseline per store (Holt-Winters with weekly seasonality)\n",
    "from tqdm import tqdm\n",
    "horizon = 90\n",
    "store_forecasts = {}\n",
    "store_residuals = {}\n",
    "store_pi = {}\n",
    "for store in tqdm(pivot.columns):\n",
    "    series = pivot[store].astype(float)\n",
    "    try:\n",
    "        model = ExponentialSmoothing(series, trend=\"add\", seasonal=\"add\", seasonal_periods=7)\n",
    "        fitted = model.fit(optimized=True, use_boxcox=False, remove_bias=False)\n",
    "        forecast = fitted.forecast(horizon)\n",
    "        resid = fitted.resid.dropna()\n",
    "        se = resid.std(ddof=1) if len(resid)>1 else np.std(series)\n",
    "        z = 1.6448536269514722\n",
    "        lower = forecast - z * se\n",
    "        upper = forecast + z * se\n",
    "        store_forecasts[store] = forecast.values\n",
    "        store_residuals[store] = resid.values\n",
    "        store_pi[store] = np.vstack([lower, upper]).T\n",
    "    except Exception as e:\n",
    "        last = series.iloc[-1]\n",
    "        store_forecasts[store] = np.repeat(last, horizon)\n",
    "        store_residuals[store] = np.zeros(max(1, len(series)-1))\n",
    "        store_pi[store] = np.vstack([np.repeat(last*0.8, horizon), np.repeat(last*1.2, horizon)]).T\n",
    "\n",
    "forecast_dates = pd.date_range(start=pivot.index[-1] + pd.Timedelta(days=1), periods=horizon, freq='D')\n",
    "forecast_df = pd.DataFrame(index=forecast_dates, columns=pivot.columns)\n",
    "for store in pivot.columns:\n",
    "    forecast_df[store] = store_forecasts[store]\n",
    "\n",
    "forecast_df.to_csv('project_outputs/bottom_level_store_forecasts.csv', index=True)\n",
    "print('Saved bottom-level store forecasts to project_outputs/bottom_level_store_forecasts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce417054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate bottom-up to regions and total\n",
    "regions = [f\"Region_{i+1}\" for i in range(n_regions)]\n",
    "region_fc_bottom = {r: forecast_df[[c for c in forecast_df.columns if c.startswith(r + \"_Store_\")]].sum(axis=1) for r in regions}\n",
    "total_fc_bottom = pd.DataFrame(region_fc_bottom, index=forecast_df.index).sum(axis=1)\n",
    "\n",
    "# Fit ETS at region & total levels (aggregated historical)\n",
    "region_hist = {}\n",
    "for r in regions:\n",
    "    cols = [c for c in pivot.columns if c.startswith(r + \"_Store_\")]\n",
    "    region_hist[r] = pivot[cols].sum(axis=1)\n",
    "region_hist_df = pd.DataFrame(region_hist, index=pivot.index)\n",
    "total_series = region_hist_df.sum(axis=1)\n",
    "\n",
    "region_ets_fc = {}\n",
    "region_ets_pi = {}\n",
    "for r in regions:\n",
    "    series = region_hist_df[r].astype(float)\n",
    "    try:\n",
    "        fitted = ExponentialSmoothing(series, trend='add', seasonal='add', seasonal_periods=7).fit(optimized=True)\n",
    "        fc = fitted.forecast(horizon)\n",
    "        resid = fitted.resid.dropna()\n",
    "        se = resid.std(ddof=1) if len(resid)>1 else np.std(series)\n",
    "        z = 1.6448536269514722\n",
    "        region_ets_fc[r] = fc.values\n",
    "        region_ets_pi[r] = np.vstack([fc - z*se, fc + z*se]).T\n",
    "    except:\n",
    "        region_ets_fc[r] = np.repeat(series.iloc[-1], horizon)\n",
    "        region_ets_pi[r] = np.vstack([np.repeat(series.iloc[-1]*0.8, horizon), np.repeat(series.iloc[-1]*1.2, horizon)]).T\n",
    "\n",
    "# Total ETS\n",
    "try:\n",
    "    fitted_total = ExponentialSmoothing(total_series, trend='add', seasonal='add', seasonal_periods=7).fit(optimized=True)\n",
    "    total_fc_ets = fitted_total.forecast(horizon)\n",
    "    total_resid = fitted_total.resid.dropna()\n",
    "    total_se = total_resid.std(ddof=1) if len(total_resid)>1 else np.std(total_series)\n",
    "    total_pi = np.vstack([total_fc_ets - 1.6448536269514722*total_se, total_fc_ets + 1.6448536269514722*total_se]).T\n",
    "except:\n",
    "    total_fc_ets = np.repeat(total_series.iloc[-1], horizon)\n",
    "    total_pi = np.vstack([np.repeat(total_series.iloc[-1]*0.8, horizon), np.repeat(total_series.iloc[-1]*1.2, horizon)]).T\n",
    "\n",
    "region_fc_bottom_df = pd.DataFrame(region_fc_bottom, index=forecast_df.index)\n",
    "region_ets_fc_df = pd.DataFrame(region_ets_fc, index=forecast_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207495c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reconcile by averaging bottom-up and aggregate ETS forecasts (50-50)\n",
    "reconciled_region = 0.5 * region_fc_bottom_df + 0.5 * region_ets_fc_df\n",
    "reconciled_total = 0.5 * total_fc_bottom + 0.5 * total_fc_ets.values\n",
    "\n",
    "top_level_out = pd.DataFrame(index=forecast_df.index)\n",
    "top_level_out['Total'] = reconciled_total.values\n",
    "for r in regions:\n",
    "    top_level_out[r] = reconciled_region[r].values\n",
    "\n",
    "# Attach 90% PIs based on ETS residual std proxies\n",
    "z = 1.6448536269514722\n",
    "for r in regions:\n",
    "    se = np.std(region_hist_df[r].diff().dropna()) if len(region_hist_df[r])>2 else 1.0\n",
    "    top_level_out[r + '_lower90'] = top_level_out[r] - z * se\n",
    "    top_level_out[r + '_upper90'] = top_level_out[r] + z * se\n",
    "\n",
    "se_total = np.std(total_series.diff().dropna()) if len(total_series)>2 else 1.0\n",
    "top_level_out['Total_lower90'] = top_level_out['Total'] - z * se_total\n",
    "top_level_out['Total_upper90'] = top_level_out['Total'] + z * se_total\n",
    "\n",
    "top_level_out.to_csv('project_outputs/top_level_forecasts_reconciled.csv', index=True)\n",
    "print('Saved reconciled top-level forecasts to project_outputs/top_level_forecasts_reconciled.csv')\n",
    "display(top_level_out.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c448f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation: simple holdout-based MASE and wMAPE at region/total levels\n",
    "holdout = 90\n",
    "true_region_hold = region_hist_df.iloc[-holdout:]\n",
    "true_total_hold = total_series.iloc[-holdout:]\n",
    "\n",
    "# naive forecast: last observed repeated\n",
    "naive_fc = pd.DataFrame(np.tile(pivot.iloc[-holdout-1].values, (holdout, 1)), columns=pivot.columns, index=true_region_hold.index)\n",
    "naive_region_hold = {r: naive_fc[[c for c in pivot.columns if c.startswith(r + '_Store_')]].sum(axis=1) for r in regions}\n",
    "naive_region_hold_df = pd.DataFrame(naive_region_hold, index=true_region_hold.index)\n",
    "naive_total_hold = naive_region_hold_df.sum(axis=1)\n",
    "\n",
    "def mase(insample, naive_forecast, actual):\n",
    "    scale = np.mean(np.abs(np.diff(insample)))\n",
    "    if scale == 0:\n",
    "        scale = 1.0\n",
    "    return np.mean(np.abs(actual - naive_forecast)) / scale\n",
    "\n",
    "def wmape(actual, forecast):\n",
    "    num = np.sum(np.abs(actual - forecast))\n",
    "    den = np.sum(np.abs(actual))\n",
    "    return num / den if den != 0 else np.nan\n",
    "\n",
    "metrics = {}\n",
    "for r in regions:\n",
    "    insample = region_hist_df[r].iloc[:-holdout].values\n",
    "    actual = true_region_hold[r].values\n",
    "    forecast_vals = naive_region_hold_df[r].values\n",
    "    metrics[r] = {'MASE': mase(insample, forecast_vals, actual), 'wMAPE': wmape(actual, forecast_vals)}\n",
    "\n",
    "insample_total = total_series.iloc[:-holdout].values\n",
    "metrics['Total'] = {'MASE': mase(insample_total, naive_total_hold.values, true_total_hold.values), 'wMAPE': wmape(true_total_hold.values, naive_total_hold.values)}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).T\n",
    "display(metrics_df)\n",
    "metrics_df.to_csv('project_outputs/evaluation_metrics.csv', index=True)\n",
    "print('Saved evaluation metrics to project_outputs/evaluation_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save a short report and README\n",
    "report_text = f\"\"\"Project: Advanced Time Series Forecasting with Hierarchical Probabilistic Modeling (Generated)\n",
    "- Data: Simulated daily sales for {n_regions} regions x {stores_per_region} stores over {years} years.\n",
    "- Models used (baseline): ETS (Holt-Winters) per store with weekly seasonality. Forecast horizon: {horizon} days.\n",
    "- Reconciliation strategies implemented: Bottom-up (summing store forecasts) and aggregate ETS averaging (50-50).\n",
    "- Evaluation: MASE and wMAPE computed on a {holdout}-day holdout for region and top-level aggregates.\n",
    "- Outputs saved in project_outputs/ folder.\n",
    "\"\"\"\n",
    "\n",
    "with open('project_outputs/project_report.txt', 'w') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "readme = \"\"\"# advanced-hpf-forecasting\n",
    "\n",
    "This repository contains code and outputs for the Advanced Time Series Forecasting project.\n",
    "\n",
    "Run the notebook `data_generation_and_modeling.ipynb` to reproduce the dataset, baseline models, reconciled forecasts, and evaluation metrics.\n",
    "\n",
    "Files in `project_outputs/` are ready for submission.\n",
    "\"\"\"\n",
    "with open('project_outputs/README.md', 'w') as f:\n",
    "    f.write(readme)\n",
    "print('Saved project_report.txt and README.md in project_outputs/')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
